{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "from openai import OpenAI\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import timeout_decorator\n",
    "import time\n",
    "import globals\n",
    "import re\n",
    "import ast\n",
    "import traceback\n",
    "COMPLETION_MODEL = globals.COMPLETION_MODEL\n",
    "API_KEY = globals.API_KEY\n",
    "\n",
    "\n",
    "# @timeout_decorator.timeout(100)\n",
    "def chat_gpt_turbo(message_our,COMPLETION_MODEL,n=1,max_tokens=3000):\n",
    "\n",
    "    client = OpenAI(api_key=API_KEY)\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "        model=COMPLETION_MODEL,\n",
    "        max_tokens = max_tokens,\n",
    "        n = n,\n",
    "        temperature = 0,\n",
    "        messages=message_our\n",
    "        )\n",
    "\n",
    "    return completion.choices[0].message\n",
    "\n",
    "\n",
    "def entity_extraction_func(text):\n",
    "    client = OpenAI(api_key=API_KEY)\n",
    "\n",
    "    system_prompt = \"\"\"\n",
    "        As an Operations Management Researcher and Natural Language Processing (NLP) Engineer, your primary task is to extract key information about suppliers from the provided text. Please follow these steps strictly:\n",
    "        1 Entity Recognition: Identify and extract all supplier names present in the text. These are the names of companies or organizations mentioned as distinct entities in the text.\n",
    "        2 Text Summary: Summarize the main activities or characteristics of each identified supplier based on the content of the text. Ensure that the summary accurately reflects the information in the text.\n",
    "        Adhere to this format:\n",
    "        {\n",
    "            'Supplier Company Name': 'Summary of content about current Supplier',\n",
    "            ...\n",
    "        }.\n",
    "        Do not add or change any content; simply fill in the relevant information.\n",
    "\n",
    "        Example input text:\n",
    "        \"...Solar Solutions recently completed a large-scale solar energy project, which successfully increased the region's renewable energy supply...\"\n",
    "        Example output:\n",
    "        { 'Solar Solutions': 'Completed a large-scale solar energy project, increasing the region's renewable energy supply'. }\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    user_prompt = f\"Here is the text: \\n {text}\" \n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo-1106\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt}\n",
    "    ]\n",
    "    )\n",
    "\n",
    "    out_put = response.choices[0].message.content\n",
    "    # print(out_put)\n",
    "\n",
    "    try:\n",
    "\n",
    "        # 使用正则表达式匹配可能的字典格式\n",
    "        dict_match = re.search(r'\\{.*?\\}', out_put, re.DOTALL)\n",
    "        # # 将匹配的文本中的单引号转换为双引号，并清理内部的双引号\n",
    "        # dict_str = dict_match.group().replace(\"'\", '\"')\n",
    "        # dict_str = re.sub(r'(?<!\\\\)\"', '', dict_str)  # 移除非转义的双引号\n",
    "\n",
    "        # 将匹配的文本处理为符合字典格式的字符串\n",
    "        dict_str = dict_match.group()\n",
    "        dict_str = re.sub(r\"[^a-zA-Z0-9{}:,. '\\\"\\[\\]]\", '', dict_str)  # 移除不合法的字符\n",
    "        dict_str = re.sub(r'(?<!\")\\b\\w+\\b(?=\":)', lambda x: '\"' + x.group() + '\"', dict_str)  # 确保键被双引号包围\n",
    "        # 尝试解析字典\n",
    "        data = ast.literal_eval(dict_str)\n",
    "    \n",
    "    except Exception as e:\n",
    "        return {}\n",
    "        # 可以在此处添加其他错误处理逻辑，如返回默认值或继续执行其他任务\n",
    "\n",
    "\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def extract_data(text, entity_extraction_func):\n",
    "    try:\n",
    "        # 使用正则表达式匹配可能的字典格式\n",
    "        dict_match = re.search(r'\\{.*?\\}', text, re.DOTALL)\n",
    "        if dict_match:\n",
    "            # 将匹配的文本中的单引号转换为双引号，并清理内部的双引号\n",
    "            # dict_str = dict_match.group().replace(\"'\", '\"')\n",
    "            # dict_str = re.sub(r'(?<!\\\\)\"', '', dict_str)  # 移除非转义的双引号\n",
    "\n",
    "            # 将匹配的文本处理为符合字典格式的字符串\n",
    "            dict_str = dict_match.group()\n",
    "            dict_str = re.sub(r\"[^a-zA-Z0-9{}:,. '\\\"\\[\\]]\", '', dict_str)  # 移除不合法的字符\n",
    "            dict_str = re.sub(r'(?<!\")\\b\\w+\\b(?=\":)', lambda x: '\"' + x.group() + '\"', dict_str)  # 确保键被双引号包围\n",
    "\n",
    "            try:\n",
    "                # 尝试解析字典\n",
    "                data = ast.literal_eval(dict_str)\n",
    "            except (SyntaxError, ValueError):\n",
    "                # 如果解析失败，使用命名实体识别函数处理文本\n",
    "                data = entity_extraction_func(text)\n",
    "        else:\n",
    "            # 如果没有匹配到字典格式，同样使用命名实体识别函数\n",
    "            data = entity_extraction_func(text)\n",
    "\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        traceback.print_exc()\n",
    "        return None \n",
    "\n",
    "def save_data(data, path, company_name, ):\n",
    "    \n",
    "        # 创建 DataFrame\n",
    "        df = pd.DataFrame(list(data.items()), columns=['Supplier', 'Content of Supplier'])\n",
    "\n",
    "        # # 添加编号列\n",
    "        # df.insert(0, 'Number', range(1, len(df) + 1))\n",
    "\n",
    "        # # 构建文件路径\n",
    "        # file_path = f'{path}/{company_name}_suppliers.csv'\n",
    "        # 构建文件路径\n",
    "        file_path = f'{path}/{company_name}.csv'\n",
    "\n",
    "        # 检查路径是否存在，如果不存在，则创建它\n",
    "        directory = os.path.dirname(file_path)\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "\n",
    "        # 检查文件是否存在，根据情况选择写入模式\n",
    "        if os.path.exists(file_path):\n",
    "            # 文件存在，使用追加模式\n",
    "            df.to_csv(file_path, mode='a', header=False, index=False, sep=\"\\t\")\n",
    "        else:\n",
    "            # 文件不存在，使用写入模式\n",
    "            df.to_csv(file_path, index=False, sep=\"\\t\")\n",
    "\n",
    "def read_and_replace_newlines(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        # 读取文件内容\n",
    "        text = file.read()\n",
    "\n",
    "    # 删除额外的空白字符和无用符号\n",
    "    text = re.sub(r'\\n+', '\\n', text)  # 替换多个连续换行符为单个换行符\n",
    "    text = re.sub(r'\\s+\\n', '\\n', text)  # 删除行末的空白字符\n",
    "    text = re.sub(r'\\n\\s+', '\\n', text)  # 删除行首的空白字符\n",
    "    text = re.sub(r'[^A-Za-z0-9.,;:\\'\"\\(\\)\\[\\]\\n]+', ' ', text)  # 删除除基本标点符号和数字字母外的所有字符\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "def split_text_into_parts(text_org, num_parts=10):\n",
    "    extracted_text = text_org\n",
    "    # 计算每部分的大致长度\n",
    "    part_length = len(extracted_text) // num_parts\n",
    "\n",
    "    # 初始化结果列表和当前部分的开始索引\n",
    "    parts = []\n",
    "    start = 0\n",
    "\n",
    "    for _ in range(num_parts - 1):\n",
    "        # 计算这部分应当结束的大致位置\n",
    "        end = start + part_length\n",
    "\n",
    "        # 如果不是在文本末尾，尽量在句子或单词结束处分割\n",
    "        if end < len(extracted_text):\n",
    "            while end < len(extracted_text) and extracted_text[end] not in \" .,;?!\":\n",
    "                end += 1\n",
    "\n",
    "        # 截取当前部分\n",
    "        parts.append(extracted_text[start:end])\n",
    "\n",
    "        # 更新下一部分的开始位置\n",
    "        start = end\n",
    "\n",
    "    # 添加最后一部分\n",
    "    parts.append(extracted_text[start:])\n",
    "\n",
    "    return parts\n",
    "\n",
    "def extract_10k_from_text(text_org):\n",
    "    \n",
    "    # 10k 特有的截取过程\n",
    "    pattern = r\"Item\\s1\\..*Item\\s1B\\.\"\n",
    "    result = re.search(pattern, text_org, re.DOTALL)\n",
    "    if result:\n",
    "        extracted_text = result.group(0)\n",
    "        len_extracted_text = len(extracted_text)\n",
    "        print(f\"{len_extracted_text=} {extracted_text}\")\n",
    "    else:\n",
    "        extracted_text = None\n",
    "        print(\"No match found.\")\n",
    "\n",
    "    return extracted_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "总共待处理文档74个\n",
      "文档列表如下：\n",
      "txt_path_list= ['AAL_6201-AAL_AMERICAN_AIRLINES_GROUP_INC_2013_12_31_aagaa10k-20131231.txt', 'AAL_6201-AAL_AMERICAN_AIRLINES_GROUP_INC_2014_12_31_d829913d10k.txt', 'AAL_6201-AAL_AMERICAN_AIRLINES_GROUP_INC_2015_12_31_d78287d10k.txt', 'AAL_6201-AAL_AMERICAN_AIRLINES_GROUP_INC_2016_12_31_d286458d10k.txt', 'AAL_6201-AAL_AMERICAN_AIRLINES_GROUP_INC_2017_12_31_a10k123117.txt', 'AAL_6201-AAL_AMERICAN_AIRLINES_GROUP_INC_2018_12_31_a10k123118.txt', 'AAL_6201-AAL_AMERICAN_AIRLINES_GROUP_INC_2019_12_31_a10k123119.txt', 'AAL_6201-AAL_AMERICAN_AIRLINES_GROUP_INC_2020_12_31_aal-20201231.txt', 'AAL_6201-AAL_AMERICAN_AIRLINES_GROUP_INC_2021_12_31_aal-20211231.txt', 'AAL_6201-AAL_AMERICAN_AIRLINES_GROUP_INC_2022_12_31_aal-20221231.txt', 'AAPL_320193-AAPL_APPLE_INC_2013_09_28_d590790d10k.txt', 'AAPL_320193-AAPL_APPLE_INC_2014_09_27_d783162d10k.txt', 'AAPL_320193-AAPL_APPLE_INC_2015_09_26_d17062d10k.txt', 'AAPL_320193-AAPL_APPLE_INC_2016_09_24_a201610-k9242016.txt', 'AAPL_320193-AAPL_APPLE_INC_2017_09_30_a10-k20179302017.txt', 'AAPL_320193-AAPL_APPLE_INC_2018_09_29_a10-k20189292018.txt', 'AAPL_320193-AAPL_APPLE_INC_2019_09_28_a10-k20199282019.txt', 'AAPL_320193-AAPL_APPLE_INC_2020_09_26_aapl-20200926.txt', 'AAPL_320193-AAPL_APPLE_INC_2021_09_25_aapl-20210925.txt', 'AAPL_320193-AAPL_APPLE_INC_2022_09_24_aapl-20220924.txt', 'AAPL_320193-AAPL_APPLE_INC_2023_09_30_aapl-20230930.txt', 'ABBV_1551152-ABBV_ABBVIE_INC_2014_12_31_a2223058z10-k.txt', 'ABBV_1551152-ABBV_ABBVIE_INC_2015_12_31_a2227341z10-k.txt', 'ABBV_1551152-ABBV_ABBVIE_INC_2016_12_31_abbv-12312016x10k.txt', 'ABBV_1551152-ABBV_ABBVIE_INC_2017_12_31_abbv-20171231x10k.txt', 'ABBV_1551152-ABBV_ABBVIE_INC_2018_12_31_abbv-20181231x10k.txt', 'ABBV_1551152-ABBV_ABBVIE_INC_2019_12_31_abbv-20191231x10k.txt', 'ABBV_1551152-ABBV_ABBVIE_INC_2020_12_31_abbv-20201231.txt', 'ABBV_1551152-ABBV_ABBVIE_INC_2021_12_31_abbv-20211231.txt', 'ABBV_1551152-ABBV_ABBVIE_INC_2022_12_31_abbv-20221231.txt', 'ABNB_1559720-ABNB_AIRBNB_INC_2020_12_31_airbnb-10k.txt', 'ABNB_1559720-ABNB_AIRBNB_INC_2021_12_31_abnb-20211231.txt', 'ABNB_1559720-ABNB_AIRBNB_INC_2022_12_31_abnb-20221231.txt', 'ABT_1800-ABT_ABBOTT_LABORATORIES_2016_12_31_a2230875z10-k.txt', 'ABT_1800-ABT_ABBOTT_LABORATORIES_2017_12_31_a2234264z10-k.txt', 'ABT_1800-ABT_ABBOTT_LABORATORIES_2018_12_31_a2237733z10-k.txt', 'ABT_1800-ABT_ABBOTT_LABORATORIES_2019_12_31_abt-20191231x10k59d41b.txt', 'ABT_1800-ABT_ABBOTT_LABORATORIES_2020_12_31_abt-20201231x10k.txt', 'ABT_1800-ABT_ABBOTT_LABORATORIES_2021_12_31_abt-20211231x10k.txt', 'ABT_1800-ABT_ABBOTT_LABORATORIES_2022_12_31_abt-20221231.txt', 'ACGL_947484-ACGL_ARCH_CAPITAL_GROUP_LTD_2011_12_31_a2207402z10-k.txt', 'ACGL_947484-ACGL_ARCH_CAPITAL_GROUP_LTD_2012_12_31_a2213076z10-k.txt', 'ACGL_947484-ACGL_ARCH_CAPITAL_GROUP_LTD_2013_12_31_a201310-k.txt', 'ACGL_947484-ACGL_ARCH_CAPITAL_GROUP_LTD_2014_12_31_a201410-k.txt', 'ACGL_947484-ACGL_ARCH_CAPITAL_GROUP_LTD_2015_12_31_a201510-k.txt', 'ACGL_947484-ACGL_ARCH_CAPITAL_GROUP_LTD_2016_12_31_a201610-k.txt', 'ACGL_947484-ACGL_ARCH_CAPITAL_GROUP_LTD_2017_12_31_a201710-k.txt', 'ACGL_947484-ACGL_ARCH_CAPITAL_GROUP_LTD_2018_12_31_a201810-k.txt', 'ACGL_947484-ACGL_ARCH_CAPITAL_GROUP_LTD_2019_12_31_a201910-k.txt', 'ACGL_947484-ACGL_ARCH_CAPITAL_GROUP_LTD_2020_12_31_acgl-20201231.txt', 'ACGL_947484-ACGL_ARCH_CAPITAL_GROUP_LTD_2021_12_31_acgl-20211231.txt', 'ACGL_947484-ACGL_ARCH_CAPITAL_GROUP_LTD_2022_12_31_acgl-20221231.txt', 'ACN_1467373-ACN_ACCENTURE_PLC_2020_08_31_acn-20200831.txt', 'ACN_1467373-ACN_ACCENTURE_PLC_2021_08_31_acn-20210831.txt', 'ACN_1467373-ACN_ACCENTURE_PLC_2022_08_31_acn-20220831.txt', 'ACN_1467373-ACN_ACCENTURE_PLC_2023_08_31_acn-20230831.txt', 'ADBE_796343-ADBE_ADOBE_INC_2015_11_27_adbe10kfy15.txt', 'ADBE_796343-ADBE_ADOBE_INC_2016_12_02_adbe10kfy16.txt', 'ADBE_796343-ADBE_ADOBE_INC_2017_12_01_adbe10kfy17.txt', 'ADBE_796343-ADBE_ADOBE_INC_2018_11_30_adbe10kfy18.txt', 'ADBE_796343-ADBE_ADOBE_INC_2019_11_29_adbe10kfy19.txt', 'ADBE_796343-ADBE_ADOBE_INC_2020_11_27_adbe-20201127.txt', 'ADBE_796343-ADBE_ADOBE_INC_2021_12_03_adbe-20211203.txt', 'ADBE_796343-ADBE_ADOBE_INC_2022_12_02_adbe-20221202.txt', 'A_1090872-A_AGILENT_TECHNOLOGIES_INC_2013_10_31_a-10312013x10k.txt', 'A_1090872-A_AGILENT_TECHNOLOGIES_INC_2014_10_31_a-10312014x10k.txt', 'A_1090872-A_AGILENT_TECHNOLOGIES_INC_2015_10_31_a-10312015x10k.txt', 'A_1090872-A_AGILENT_TECHNOLOGIES_INC_2016_10_31_a-10312016x10k.txt', 'A_1090872-A_AGILENT_TECHNOLOGIES_INC_2017_10_31_a-10312017x10k.txt', 'A_1090872-A_AGILENT_TECHNOLOGIES_INC_2018_10_31_a-10312018x10k.txt', 'A_1090872-A_AGILENT_TECHNOLOGIES_INC_2019_10_31_a-10312019x10k.txt', 'A_1090872-A_AGILENT_TECHNOLOGIES_INC_2020_10_31_a-20201031.txt', 'A_1090872-A_AGILENT_TECHNOLOGIES_INC_2021_10_31_a-20211031.txt', 'A_1090872-A_AGILENT_TECHNOLOGIES_INC_2022_10_31_a-20221031.txt']\n"
     ]
    }
   ],
   "source": [
    "is_10k = True # TODO 配置当前代码运行什么txt的llm程序\n",
    "            # True运行10k \n",
    "            # False 运行 sustainable report\n",
    "\n",
    "if is_10k:\n",
    "    folder_path = '10k'  # 10k 部分\n",
    "else:\n",
    "    folder_path = 'PDF_Convert_Txts' # 年报部分\n",
    "\n",
    "txt_path_list = os.listdir(f\"{folder_path}\")\n",
    "txt_path_list = sorted(txt_path_list)\n",
    "\n",
    "\n",
    "\n",
    "if is_10k:\n",
    "    existed_report_path = f\"./Supply_10K_After_GPT/{COMPLETION_MODEL}\"\n",
    "else:\n",
    "    existed_report_path = f\"./Supply_sustainable_report_After_GPT/{COMPLETION_MODEL}\"\n",
    "\n",
    "\n",
    "print(f\"总共待处理文档{len(txt_path_list)}个\\n文档列表如下：\\n{txt_path_list= }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "选取处理文档5个\n",
      " 文档列表如下：\n",
      "txt_path_list= ['AAL_6201-AAL_AMERICAN_AIRLINES_GROUP_INC_2013_12_31_aagaa10k-20131231.txt', 'AAL_6201-AAL_AMERICAN_AIRLINES_GROUP_INC_2014_12_31_d829913d10k.txt', 'AAL_6201-AAL_AMERICAN_AIRLINES_GROUP_INC_2015_12_31_d78287d10k.txt', 'AAL_6201-AAL_AMERICAN_AIRLINES_GROUP_INC_2016_12_31_d286458d10k.txt', 'AAL_6201-AAL_AMERICAN_AIRLINES_GROUP_INC_2017_12_31_a10k123117.txt']\n"
     ]
    }
   ],
   "source": [
    "text_file_num = 5   # TODO 配置你想要测试的文档数量\n",
    "org_txt_path_list = txt_path_list.copy()\n",
    "txt_path_list = txt_path_list[:text_file_num] \n",
    "\n",
    "# 如果不想要配置文档数量并测试，而是开始全部爬取，则取下面的注释 TODO\n",
    "# txt_path_list = org_txt_path_list\n",
    "\n",
    "\n",
    "print(f\"选取处理文档{len(txt_path_list)}个\\n 文档列表如下：\\n{txt_path_list= }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set()\n",
      "从文档AAL_6201-AAL_AMERICAN_AIRLINES_GROUP_INC_2014_12_31_d829913d10k.csv开始\n",
      "File ./Supply_10K_After_GPT/gpt-3.5-turbo-16k/AAL_6201-AAL_AMERICAN_AIRLINES_GROUP_INC_2014_12_31_d829913d10k.csv has been deleted.\n",
      "开始处理 company_name AAL_6201-AAL_AMERICAN_AIRLINES_GROUP_INC_2013_12_31_aagaa10k-20131231.txt\n",
      "len_extracted_text=45 Item 1.Business5Item1A.Risk Factors25Item 1B.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\dylan\\anaconda3\\Lib\\site-packages\\httpcore\\_exceptions.py\", line 10, in map_exceptions\n",
      "    yield\n",
      "  File \"c:\\Users\\dylan\\anaconda3\\Lib\\site-packages\\httpcore\\_backends\\sync.py\", line 206, in connect_tcp\n",
      "    sock = socket.create_connection(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\dylan\\anaconda3\\Lib\\socket.py\", line 851, in create_connection\n",
      "    raise exceptions[0]\n",
      "  File \"c:\\Users\\dylan\\anaconda3\\Lib\\socket.py\", line 836, in create_connection\n",
      "    sock.connect(sa)\n",
      "TimeoutError: timed out\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\dylan\\anaconda3\\Lib\\site-packages\\httpx\\_transports\\default.py\", line 66, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"c:\\Users\\dylan\\anaconda3\\Lib\\site-packages\\httpx\\_transports\\default.py\", line 228, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\dylan\\anaconda3\\Lib\\site-packages\\httpcore\\_sync\\connection_pool.py\", line 268, in handle_request\n",
      "    raise exc\n",
      "  File \"c:\\Users\\dylan\\anaconda3\\Lib\\site-packages\\httpcore\\_sync\\connection_pool.py\", line 251, in handle_request\n",
      "    response = connection.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\dylan\\anaconda3\\Lib\\site-packages\\httpcore\\_sync\\connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"c:\\Users\\dylan\\anaconda3\\Lib\\site-packages\\httpcore\\_sync\\connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\dylan\\anaconda3\\Lib\\site-packages\\httpcore\\_sync\\connection.py\", line 124, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\dylan\\anaconda3\\Lib\\site-packages\\httpcore\\_backends\\sync.py\", line 205, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"c:\\Users\\dylan\\anaconda3\\Lib\\contextlib.py\", line 155, in __exit__\n",
      "    self.gen.throw(typ, value, traceback)\n",
      "  File \"c:\\Users\\dylan\\anaconda3\\Lib\\site-packages\\httpcore\\_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectTimeout: timed out\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\dylan\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py\", line 877, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\dylan\\anaconda3\\Lib\\site-packages\\httpx\\_client.py\", line 901, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\dylan\\anaconda3\\Lib\\site-packages\\httpx\\_client.py\", line 929, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\dylan\\anaconda3\\Lib\\site-packages\\httpx\\_client.py\", line 966, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\dylan\\anaconda3\\Lib\\site-packages\\httpx\\_client.py\", line 1002, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\dylan\\anaconda3\\Lib\\site-packages\\httpx\\_transports\\default.py\", line 227, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"c:\\Users\\dylan\\anaconda3\\Lib\\contextlib.py\", line 155, in __exit__\n",
      "    self.gen.throw(typ, value, traceback)\n",
      "  File \"c:\\Users\\dylan\\anaconda3\\Lib\\site-packages\\httpx\\_transports\\default.py\", line 83, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectTimeout: timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\dylan\\anaconda3\\Lib\\site-packages\\httpcore\\_exceptions.py\", line 10, in map_exceptions\n",
      "    yield\n",
      "  File \"c:\\Users\\dylan\\anaconda3\\Lib\\site-packages\\httpcore\\_backends\\sync.py\", line 206, in connect_tcp\n",
      "    sock = socket.create_connection(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\dylan\\anaconda3\\Lib\\socket.py\", line 851, in create_connection\n",
      "    raise exceptions[0]\n",
      "  File \"c:\\Users\\dylan\\anaconda3\\Lib\\socket.py\", line 836, in create_connection\n",
      "    sock.connect(sa)\n",
      "TimeoutError: timed out\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\dylan\\anaconda3\\Lib\\site-packages\\httpx\\_transports\\default.py\", line 66, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"c:\\Users\\dylan\\anaconda3\\Lib\\site-packages\\httpx\\_transports\\default.py\", line 228, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\dylan\\anaconda3\\Lib\\site-packages\\httpcore\\_sync\\connection_pool.py\", line 268, in handle_request\n",
      "    raise exc\n",
      "  File \"c:\\Users\\dylan\\anaconda3\\Lib\\site-packages\\httpcore\\_sync\\connection_pool.py\", line 251, in handle_request\n",
      "    response = connection.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\dylan\\anaconda3\\Lib\\site-packages\\httpcore\\_sync\\connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"c:\\Users\\dylan\\anaconda3\\Lib\\site-packages\\httpcore\\_sync\\connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\dylan\\anaconda3\\Lib\\site-packages\\httpcore\\_sync\\connection.py\", line 124, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\dylan\\anaconda3\\Lib\\site-packages\\httpcore\\_backends\\sync.py\", line 205, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"c:\\Users\\dylan\\anaconda3\\Lib\\contextlib.py\", line 155, in __exit__\n",
      "    self.gen.throw(typ, value, traceback)\n",
      "  File \"c:\\Users\\dylan\\anaconda3\\Lib\\site-packages\\httpcore\\_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectTimeout: timed out\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\dylan\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py\", line 877, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\dylan\\anaconda3\\Lib\\site-packages\\httpx\\_client.py\", line 901, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\dylan\\anaconda3\\Lib\\site-packages\\httpx\\_client.py\", line 929, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\dylan\\anaconda3\\Lib\\site-packages\\httpx\\_client.py\", line 966, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\dylan\\anaconda3\\Lib\\site-packages\\httpx\\_client.py\", line 1002, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\dylan\\anaconda3\\Lib\\site-packages\\httpx\\_transports\\default.py\", line 227, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"c:\\Users\\dylan\\anaconda3\\Lib\\contextlib.py\", line 155, in __exit__\n",
      "    self.gen.throw(typ, value, traceback)\n",
      "  File \"c:\\Users\\dylan\\anaconda3\\Lib\\site-packages\\httpx\\_transports\\default.py\", line 83, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectTimeout: timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\dylan\\anaconda3\\Lib\\site-packages\\httpcore\\_exceptions.py\", line 10, in map_exceptions\n",
      "    yield\n",
      "  File \"c:\\Users\\dylan\\anaconda3\\Lib\\site-packages\\httpcore\\_backends\\sync.py\", line 206, in connect_tcp\n",
      "    sock = socket.create_connection(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\dylan\\anaconda3\\Lib\\socket.py\", line 851, in create_connection\n",
      "    raise exceptions[0]\n",
      "  File \"c:\\Users\\dylan\\anaconda3\\Lib\\socket.py\", line 836, in create_connection\n",
      "    sock.connect(sa)\n",
      "TimeoutError: timed out\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\dylan\\anaconda3\\Lib\\site-packages\\httpx\\_transports\\default.py\", line 66, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"c:\\Users\\dylan\\anaconda3\\Lib\\site-packages\\httpx\\_transports\\default.py\", line 228, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\dylan\\anaconda3\\Lib\\site-packages\\httpcore\\_sync\\connection_pool.py\", line 268, in handle_request\n",
      "    raise exc\n",
      "  File \"c:\\Users\\dylan\\anaconda3\\Lib\\site-packages\\httpcore\\_sync\\connection_pool.py\", line 251, in handle_request\n",
      "    response = connection.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\dylan\\anaconda3\\Lib\\site-packages\\httpcore\\_sync\\connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"c:\\Users\\dylan\\anaconda3\\Lib\\site-packages\\httpcore\\_sync\\connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\dylan\\anaconda3\\Lib\\site-packages\\httpcore\\_sync\\connection.py\", line 124, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\dylan\\anaconda3\\Lib\\site-packages\\httpcore\\_backends\\sync.py\", line 205, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"c:\\Users\\dylan\\anaconda3\\Lib\\contextlib.py\", line 155, in __exit__\n",
      "    self.gen.throw(typ, value, traceback)\n",
      "  File \"c:\\Users\\dylan\\anaconda3\\Lib\\site-packages\\httpcore\\_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectTimeout: timed out\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\dylan\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py\", line 877, in _request\n",
      "    response = self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\dylan\\anaconda3\\Lib\\site-packages\\httpx\\_client.py\", line 901, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\dylan\\anaconda3\\Lib\\site-packages\\httpx\\_client.py\", line 929, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\dylan\\anaconda3\\Lib\\site-packages\\httpx\\_client.py\", line 966, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\dylan\\anaconda3\\Lib\\site-packages\\httpx\\_client.py\", line 1002, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\dylan\\anaconda3\\Lib\\site-packages\\httpx\\_transports\\default.py\", line 227, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"c:\\Users\\dylan\\anaconda3\\Lib\\contextlib.py\", line 155, in __exit__\n",
      "    self.gen.throw(typ, value, traceback)\n",
      "  File \"c:\\Users\\dylan\\anaconda3\\Lib\\site-packages\\httpx\\_transports\\default.py\", line 83, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectTimeout: timed out\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\dylan\\AppData\\Local\\Temp\\ipykernel_20540\\1474179.py\", line 76, in <module>\n",
      "    output = chat_gpt_turbo(message_our, COMPLETION_MODEL).content\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\dylan\\AppData\\Local\\Temp\\ipykernel_20540\\1418857773.py\", line 21, in chat_gpt_turbo\n",
      "    completion = client.chat.completions.create(\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\dylan\\anaconda3\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 303, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\dylan\\anaconda3\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 598, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\dylan\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py\", line 1088, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\dylan\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py\", line 853, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\dylan\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py\", line 884, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\dylan\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py\", line 958, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\dylan\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py\", line 884, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\dylan\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py\", line 958, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\dylan\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py\", line 893, in _request\n",
      "    raise APITimeoutError(request=request) from err\n",
      "openai.APITimeoutError: Request timed out.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no response from gpt\n"
     ]
    }
   ],
   "source": [
    "# 断点重续\n",
    "try:\n",
    "    existed_reports = set()\n",
    "    existed_report_list = os.listdir(existed_report_path)\n",
    "    for existed_report in existed_report_list[:-1]:\n",
    "        # existed_report = existed_report.replace(\"_suppliers\", \"\")\n",
    "        existed_report = existed_report.split(\".\")[0]\n",
    "        existed_reports.add(existed_report)\n",
    "    print(existed_reports)\n",
    "\n",
    "    if len(existed_report_list) >= 1:\n",
    "        last_report = existed_report_list[-1] # 删除，重新生成，以保证完整性\n",
    "        print(f\"从文档{last_report}开始\")\n",
    "        import os\n",
    "        last_file_path = f\"{existed_report_path}/{last_report}\"# 替换为要删除的文件的路径\n",
    "        # print(last_file_path)\n",
    "        # 检查文件是否存在\n",
    "        if os.path.exists(last_file_path):\n",
    "            os.remove(last_file_path)\n",
    "            print(f\"File {last_file_path} has been deleted.\")\n",
    "        else:\n",
    "            print(f\"File {last_file_path} does not exist.\")\n",
    "\n",
    "except:\n",
    "    pass\n",
    "\n",
    "\n",
    "for txt_path in txt_path_list:\n",
    "    company_name = txt_path.replace(\".txt\", \"\")\n",
    "    print(\"开始处理 company_name\", txt_path)\n",
    "    if company_name in existed_reports:\n",
    "        continue\n",
    "    modified_text = read_and_replace_newlines(f\"{folder_path}/{txt_path}\")\n",
    "\n",
    "    extract_text = extract_10k_from_text(modified_text) # TODO 10k 特有步骤，非10k 可以删除\n",
    "    modified_text_parts = split_text_into_parts(extract_text)\n",
    "\n",
    "    system_prompt = \"\"\"\n",
    "        As an operations management researcher, \\\n",
    "        your task is to extract the names of suppliers from a company's provided responsibility report and summarize the overall situation of the supplier as mentioned in the report.\\\n",
    "        Strictly adhere to the following example format, without adding or altering any content\n",
    "        If it does not exist any supplier companies, an empty {} is returned.\\\n",
    "        If it does not exist any supplier companies, following format string is returned.    :\\\n",
    "        {\n",
    "            'Supplier Company Name': 'Summary of content about current Supplier',\n",
    "            ...\n",
    "        }.\\\n",
    "        Here is an output example:\\\n",
    "        {\n",
    "            'Umicore Finland Oy': 'Conformant refiner sourcing cobalt for Gigafactory Nevada and Fremont external cell sourcing, located in Finland.',\n",
    "            'Murrin Murrin Nickel Cobalt Plant': 'Conformant refiner sourcing cobalt for Gigafactory Nevada and Fremont external cell sourcing, located in Australia.',\n",
    "            ...\n",
    "        }.\\\n",
    "        Any deviation from this format will not be accepted. \\\n",
    "        Any information beyond this format will be disregarded. \\\n",
    "        Please ensure your response strictly follows this structure. \\\n",
    "        Extract the names of the suppliers accurately based on the report's content, and output them in the specified format.\n",
    "\n",
    "\"\"\"\n",
    "    to_save_data=dict()\n",
    "    for modified_text_item in modified_text_parts:\n",
    "\n",
    "        message_our = [\n",
    "            {\"role\": \"system\", \"content\": system_prompt}\n",
    "        ]\n",
    "\n",
    "\n",
    "        user_prompt = f\"{modified_text_item}\" \n",
    "        user_prompt_dic = {\"role\": \"user\", \"content\": user_prompt}\n",
    "        message_our.append(user_prompt_dic)\n",
    "\n",
    "        attempts = 0\n",
    "        success = False\n",
    "\n",
    "        while attempts < 5 and not success:\n",
    "            try:\n",
    "                output = chat_gpt_turbo(message_our, COMPLETION_MODEL).content\n",
    "                success = True\n",
    "                print(\"output\", output)\n",
    "            except Exception as ex:\n",
    "                traceback.print_exc()\n",
    "                print('no response from gpt')\n",
    "                time.sleep(5)\n",
    "                attempts += 1\n",
    "                if attempts == 3:\n",
    "                    break\n",
    "            \n",
    "\n",
    "        import re\n",
    "        if output and re.match(r'^\\s*\\{\\s*\\}\\s*$', output) is None:\n",
    "            data = extract_data(output, entity_extraction_func)\n",
    "\n",
    "        print(f\"from output extract {data=}\")\n",
    "        if isinstance(data, dict):\n",
    "            to_save_data.update(data)\n",
    "        else:\n",
    "            print(\"data is not instance some error happend\")\n",
    "\n",
    "        save_data(to_save_data, existed_report_path, company_name)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "cannot access local variable 'company_name' where it is not associated with a value",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\dylan\\Desktop\\code\\get_web_pdf_and_get_supplier_from_it\\src_code\\split_10k_merge_llm_prodict_and_process.ipynb Cell 5\u001b[0m line \u001b[0;36m9\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dylan/Desktop/code/get_web_pdf_and_get_supplier_from_it/src_code/split_10k_merge_llm_prodict_and_process.ipynb#W6sZmlsZQ%3D%3D?line=92'>93</a>\u001b[0m                 os\u001b[39m.\u001b[39mmakedirs(directory)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dylan/Desktop/code/get_web_pdf_and_get_supplier_from_it/src_code/split_10k_merge_llm_prodict_and_process.ipynb#W6sZmlsZQ%3D%3D?line=93'>94</a>\u001b[0m             result_df\u001b[39m.\u001b[39mto_csv(new_file_path, index\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,sep\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/dylan/Desktop/code/get_web_pdf_and_get_supplier_from_it/src_code/split_10k_merge_llm_prodict_and_process.ipynb#W6sZmlsZQ%3D%3D?line=96'>97</a>\u001b[0m process_all(existed_report_path)\n",
      "\u001b[1;32mc:\\Users\\dylan\\Desktop\\code\\get_web_pdf_and_get_supplier_from_it\\src_code\\split_10k_merge_llm_prodict_and_process.ipynb Cell 5\u001b[0m line \u001b[0;36m8\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dylan/Desktop/code/get_web_pdf_and_get_supplier_from_it/src_code/split_10k_merge_llm_prodict_and_process.ipynb#W6sZmlsZQ%3D%3D?line=75'>76</a>\u001b[0m result_df \u001b[39m=\u001b[39m process_supplier_data(df)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dylan/Desktop/code/get_web_pdf_and_get_supplier_from_it/src_code/split_10k_merge_llm_prodict_and_process.ipynb#W6sZmlsZQ%3D%3D?line=77'>78</a>\u001b[0m \u001b[39m# 把company_name, year, type加到result_df后，每一行的值都相同\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dylan/Desktop/code/get_web_pdf_and_get_supplier_from_it/src_code/split_10k_merge_llm_prodict_and_process.ipynb#W6sZmlsZQ%3D%3D?line=78'>79</a>\u001b[0m \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dylan/Desktop/code/get_web_pdf_and_get_supplier_from_it/src_code/split_10k_merge_llm_prodict_and_process.ipynb#W6sZmlsZQ%3D%3D?line=79'>80</a>\u001b[0m \u001b[39m# 向结果DataFrame中添加公司名、年份和类型的列\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/dylan/Desktop/code/get_web_pdf_and_get_supplier_from_it/src_code/split_10k_merge_llm_prodict_and_process.ipynb#W6sZmlsZQ%3D%3D?line=80'>81</a>\u001b[0m result_df[\u001b[39m'\u001b[39m\u001b[39mCompany\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m company_name\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dylan/Desktop/code/get_web_pdf_and_get_supplier_from_it/src_code/split_10k_merge_llm_prodict_and_process.ipynb#W6sZmlsZQ%3D%3D?line=81'>82</a>\u001b[0m result_df[\u001b[39m'\u001b[39m\u001b[39mYear\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m year\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dylan/Desktop/code/get_web_pdf_and_get_supplier_from_it/src_code/split_10k_merge_llm_prodict_and_process.ipynb#W6sZmlsZQ%3D%3D?line=82'>83</a>\u001b[0m result_df[\u001b[39m'\u001b[39m\u001b[39mReport_type\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m report_type\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: cannot access local variable 'company_name' where it is not associated with a value"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "\n",
    "\n",
    "\n",
    "# def standardize_supplier_name(name):\n",
    "#     \"\"\" 标准化供应商名称，可根据需要调整正则表达式 \"\"\"\n",
    "#     # 示例：将简写转换为完整名称，如“Tesla”转换为“Tesla Inc.”\n",
    "#     # 注意：这里的规则需要根据具体情况来定制\n",
    "#     name = re.sub(r'\\bTesla\\b', 'Tesla Inc.', name)\n",
    "#     return name\n",
    "\n",
    "def process_supplier_data(df):\n",
    "\n",
    "    # # 标准化供应商名称\n",
    "    # df['Supplier'] = df['Supplier'].apply(standardize_supplier_name)\n",
    "\n",
    "    # 确保所有的内容都是字符串类型\n",
    "    df['Content of Supplier'] = df['Content of Supplier'].astype(str)\n",
    "\n",
    "\n",
    "    # 合并相同的供应商行，拼接内容\n",
    "    df = df.groupby('Supplier')['Content of Supplier'].apply(lambda x: ' '.join(x)).reset_index()\n",
    "\n",
    "    # 在结尾添加一行编号\n",
    "    df['Number'] = range(1, len(df) + 1)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "def process_all(folder_path):\n",
    "\n",
    "    # 遍历文件夹中的所有文件\n",
    "    for filename in os.listdir(folder_path):\n",
    "        print(f\"{filename=}\")\n",
    "        if filename.endswith('.csv'):  # 确保文件是CSV格式\n",
    "\n",
    "            if not is_10k and filename.split(\".\")[0].endswith('CSR'):\n",
    "            \n",
    "                company_name = filename.split(\".\")[0].split(\"_\")[1]\n",
    "                year = filename.split(\".\")[0].split(\"_\")[2]\n",
    "                report_type = filename.split(\".\")[0].split(\"_\")[-1]\n",
    "                # print(company_name)\n",
    "                # print(year)\n",
    "                # print(report_type)\n",
    "            elif is_10k:\n",
    "                \n",
    "                # # 使用正则表达式匹配日期和年份部分\n",
    "                pattern = r\"(\\d{4})_(\\d{2}_\\d{2})\"\n",
    "                result = re.search(pattern, filename)\n",
    "\n",
    "                if result:\n",
    "                    year = result.group(1)\n",
    "                    date = result.group(2)\n",
    "                    print(\"Year:\", year)\n",
    "                    print(\"Date:\", date)\n",
    "                else:\n",
    "                    print(\"No match found.\")\n",
    "                result = re.search(pattern, filename)\n",
    "                tic = filename.split(\"-\")[0].split(\"_\")[0]\n",
    "                tic_company_name_pattern = r\"(\\w+)_(\\d{4}_\\d{2}_\\d{2})\"\n",
    "                tic_company_name_res = re.search(tic_company_name_pattern, filename)\n",
    "                if tic_company_name_res:\n",
    "                    company_name = result.group(1).strip(tic).strip(\"_\")\n",
    "                    print(\"TIC:\", tic)\n",
    "                    print(\"Company Name:\", company_name)\n",
    "                else:\n",
    "                    print(\"No match found.\")\n",
    "                company_name = company_name\n",
    "                report_type = \"10k\" if is_10k else \"sustainable report\"\n",
    "                # print(company_name)\n",
    "                # print(year)\n",
    "                # print(report_type)\n",
    "\n",
    "\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            df = pd.read_csv(file_path, sep=\"\\t\")\n",
    "\n",
    "            # 合并相同的\n",
    "            result_df = process_supplier_data(df)\n",
    "\n",
    "            # 把company_name, year, type加到result_df后，每一行的值都相同\n",
    "\n",
    "            # 向结果DataFrame中添加公司名、年份和类型的列\n",
    "            result_df['Company'] = company_name\n",
    "            result_df['Year'] = year\n",
    "            result_df['Report_type'] = report_type\n",
    "\n",
    "            # 需要代码补全\n",
    "\n",
    "            # 可以选择将结果保存回文件\n",
    "            new_folder_path = f\"{folder_path}_post\"\n",
    "            new_file_path = os.path.join(new_folder_path, f\"{filename}\")\n",
    "            # 检查路径是否存在，如果不存在，则创建它\n",
    "            directory = os.path.dirname(new_file_path)\n",
    "            if not os.path.exists(directory):\n",
    "                os.makedirs(directory)\n",
    "            result_df.to_csv(new_file_path, index=False,sep=\"\\t\")\n",
    "\n",
    "\n",
    "process_all(\"./Supply_After_GPT/gpt-3.5-turbo-1106\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
