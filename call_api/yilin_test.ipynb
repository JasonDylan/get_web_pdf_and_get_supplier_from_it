{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4514615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text extracted and saved successfully.\n"
     ]
    }
   ],
   "source": [
    "import PyPDF2\n",
    "import re\n",
    "def read_text_file(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'r') as file:\n",
    "            content = file.read()\n",
    "        return content\n",
    "    except FileNotFoundError:\n",
    "        print(\"指定的文件路径不存在或无法访问。\")\n",
    "        return None\n",
    "    \n",
    "def extract_text_between_items(pdf_file_path, start_item, end_item):\n",
    "    # Step 1: Convert PDF to text\n",
    "    text = read_text_file(pdf_file_path)\n",
    "\n",
    "    # Step 2: Find indices of start and end items\n",
    "    # start_indices = [match.start() for match in re.finditer(re.escape(start_item), text)]\n",
    "    # end_indices = [match.start() for match in re.finditer(re.escape(end_item), text)]\n",
    "\n",
    "    # Step 3: Extract text between the second occurrence of start item and the second occurrence of end item\n",
    "    # if len(start_indices) >= 2 and len(end_indices) >= 2:\n",
    "    #     start_index = start_indices[1] + len(start_item)\n",
    "    #     end_index = end_indices[1]\n",
    "    #     extracted_text = text[start_index:end_index].strip()\n",
    "    #     return extracted_text\n",
    "    # else:\n",
    "    #     return None\n",
    "    \n",
    "    return text\n",
    "\n",
    "def extract_text_from_pdf(pdf_file_path):\n",
    "    # Open the PDF file in read-binary mode\n",
    "    with open(pdf_file_path, 'rb') as file:\n",
    "        # Create a PDF reader object\n",
    "        pdf_reader = PyPDF2.PdfReader(file)\n",
    "        \n",
    "        # Extract text from each page\n",
    "        text = ''\n",
    "        for page_num in range(len(pdf_reader.pages)):\n",
    "            page = pdf_reader.pages[page_num]\n",
    "            text += page.extract_text()\n",
    "        text=text.lower()\n",
    "        return text\n",
    "\n",
    "pdf_file_path = \"D:/Users/sjc/get_web_pdf_and_get_supplier_from_it/data/EDGAR/ORG/AMD_2488/AMD_ADVANCED_MICRO_DEVICES_2018_12_29_amd-12292018x10k.txt\"\n",
    "start_item = \"UNITED STATESSECURITIES\"\n",
    "end_item = \"manufactured at process node\"\n",
    "\n",
    "# Extract text between the second occurrence of start item and the second occurrence of end item\n",
    "# extracted_text = extract_text_between_items(pdf_file_path, start_item, end_item)\n",
    "extracted_text = read_text_file(pdf_file_path)\n",
    "if extracted_text:\n",
    "    output_file_path = \"./RESULT/extracted_text.txt\"\n",
    "    with open(output_file_path, 'w', encoding='utf-8') as file:\n",
    "        file.write(extracted_text)\n",
    "    print(\"Text extracted and saved successfully.\")\n",
    "else:\n",
    "    print(\"Could not find the specified start and end items in the PDF.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1949a1c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word count: 64459\n"
     ]
    }
   ],
   "source": [
    "def count_words_in_text_file(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "        word_count = len(text.split())\n",
    "        return word_count\n",
    "\n",
    "extracted_text_file_path = \"./RESULT/extracted_text.txt\"\n",
    "\n",
    "# 统计提取文本文件中的字数\n",
    "word_count = count_words_in_text_file(extracted_text_file_path)\n",
    "print(\"Word count:\", word_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "afc63e53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response='[]'\n",
      "response='[]'\n",
      "response='[]'\n",
      "response=\"[{'supplier_company_name': 'Sony Interactive Entertainment LLC'}, {'supplier_company_name': 'Microsoft Corporation'}, {'supplier_company_name': 'Nvidia Corporation'}, {'supplier_company_name': 'ARM Holdings'}, {'supplier_company_name': 'Intel Corporation'}]\"\n",
      "response=\"[{'supplier_company_name': 'GLOBALFOUNDRIES Inc.'}, {'supplier_company_name': 'Taiwan Semiconductor Manufacturing Company'}, {'supplier_company_name': 'third-party manufacturers'}, {'supplier_company_name': 'Tongfu Fujitsu Microelectronics Co., Ltd.'}, {'supplier_company_name': 'Intel'}]\"\n",
      "response=\"[{'supplier_company_name': 'Intel'}, {'supplier_company_name': 'Nvidia Corporation'}, {'supplier_company_name': 'Taiwan Semiconductor Co., Ltd.'}]\"\n",
      "response='[]'\n",
      "response='[]'\n",
      "response=\"[{'supplier_company_name': 'Sony'}, {'supplier_company_name': 'Microsoft'}, {'supplier_company_name': 'Intel'}, {'supplier_company_name': 'Microsoft Corporation'}]\"\n",
      "response='[]'\n",
      "response='[]'\n",
      "response='[]'\n",
      "response=\"which the carrying value of the reporting unit exceeds its fair value. If an impairment charge is recognized, it is allocated to the reporting unit's goodwill on a pro-rata basis.\\n\\nIncome Taxes. We are subject to income taxes in the United States and various foreign jurisdictions. Significant judgment is required in determining our provision for income taxes, deferred tax assets and liabilities, and any valuation allowance recorded against our net deferred tax assets. We must make estimates and judgments regarding the ultimate resolution of any uncertain tax positions taken in our income tax returns. These estimates and judgments are based on our interpretation of tax laws and regulations and our assessment of the likelihood of the tax positions being sustained upon examination by tax authorities. We adjust these estimates and judgments as new information becomes available, which may impact our provision for income taxes and effective tax rate.\\n\\nSuppliers mentioned in the report: None.\"\n",
      "response='[]'\n",
      "response='[]'\n",
      "response='[]'\n",
      "response='[]'\n",
      "response='[]'\n",
      "response=\"[{'supplier_company_name': 'GLOBALFOUNDRIES Inc.'}]\"\n",
      "response='[]'\n",
      "response='The report does not mention any suppliers.'\n",
      "response='[]'\n",
      "response='[]'\n",
      "response='[]'\n",
      "response=\"[{'supplier_company_name': 'Quarterhill Inc.'}]\"\n",
      "response='[]'\n",
      "response='[]'\n",
      "response='[]'\n",
      "response=\"[{'supplier_company_name': 'Bank of America, N.A.'}, {'supplier_company_name': 'GLOBALFOUNDRIES, Inc.'}, {'supplier_company_name': 'GLOBALFOUNDRIES U.S., Inc.'}, {'supplier_company_name': 'Advanced Technology Investment Company LLC'}, {'supplier_company_name': 'West Coast Hitech L.P.'}, {'supplier_company_name': 'AMD International Sales & Service, Ltd.'}, {'supplier_company_name': 'ATI Technologies ULC'}]\"\n",
      "'ATI\n",
      "'AMD\n",
      "N.A.'},\n",
      "U.S.,\n",
      "ULC'}]\n",
      "LLC'},\n",
      "'GLOBALFOUNDRIES,\n",
      "L.P.'},\n",
      "'GLOBALFOUNDRIES\n",
      "'ARM\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "openai.api_key = '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'\n",
    "\n",
    "def split_text_into_segments(text, max_segment_length):\n",
    "    segments = []\n",
    "    current_segment = \"\"\n",
    "\n",
    "    for word in text.split():\n",
    "        if len(current_segment) + len(word) + 1 <= max_segment_length:\n",
    "            current_segment += word + \" \"\n",
    "        else:\n",
    "            segments.append(current_segment.strip())\n",
    "            current_segment = word + \" \"\n",
    "    \n",
    "    if current_segment:\n",
    "        segments.append(current_segment.strip())\n",
    "\n",
    "    return segments\n",
    "\n",
    "def generate_response(prompt):\n",
    "    system_prompt = \"\"\"\n",
    "        As an operations management researcher, \n",
    "        your task is to extract the names of suppliers from a company's provided responsibility report and summarize the overall situation of the company as mentioned in the report.\n",
    "        Strictly adhere to the following example format, without adding or altering any content:\n",
    "        if No suppliers mentioned in the report, Example Output:\n",
    "        [].\n",
    "        if suppliers mentioned in the report, Example Output:\n",
    "        [{'supplier_company_name': 'Name of the first supplier'},{'supplier_company_name': 'Name of the second supplier'},...,{'supplier_company_name': 'Name of the Nth supplier'}].\n",
    "        Any deviation from this format will not be accepted. \n",
    "        Any information beyond this format will be disregarded. \n",
    "        Please ensure your response strictly follows this structure. \n",
    "        Extract the names of the suppliers accurately based on the report's content, and output them in the specified format.\n",
    "\n",
    "\"\"\"\n",
    "    message = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt}\n",
    "    ]\n",
    "    \n",
    "    user_prompt_dic = {\"role\": \"user\", \"content\": f\"{prompt}\"}\n",
    "    message.append(user_prompt_dic)\n",
    "    \n",
    "    #COMPLETION_MODEL = \"gpt-4-1106-preview\" # 选用超长\n",
    "    COMPLETION_MODEL = \"gpt-3.5-turbo-16k\" # 选用长\n",
    "    response = openai.ChatCompletion.create(\n",
    "        \n",
    "        model=COMPLETION_MODEL,\n",
    "        messages=message,\n",
    "        max_tokens=300,\n",
    "        n=1,\n",
    "        stop=None,\n",
    "        temperature=0\n",
    "    )\n",
    "    return response.choices[0].message['content']\n",
    "\n",
    "def identify_vendors_in_text(text):\n",
    "    segments = split_text_into_segments(text, 15000)\n",
    "    identified_vendors = set()\n",
    "\n",
    "    for segment in segments:\n",
    "        prompt = segment\n",
    "        response = generate_response(prompt)\n",
    "        print(f\"{response=}\")\n",
    "        identified_vendors.update(extract_vendors_from_response(response))\n",
    "    \n",
    "    return identified_vendors\n",
    "\n",
    "def extract_vendors_from_response(response):\n",
    "    # Placeholder implementation, replace with your logic to extract vendors from the response\n",
    "    vendors = set()\n",
    "    # Example placeholder logic: extract any uppercase words from the response\n",
    "    words = response.split()\n",
    "    for word in words:\n",
    "        if word.isupper():\n",
    "            vendors.add(word)\n",
    "    return vendors\n",
    "\n",
    "# Read the text file\n",
    "text_file_path = \"./RESULT/extracted_text.txt\"\n",
    "with open(text_file_path, 'r', encoding='utf-8') as file:\n",
    "    text = file.read()\n",
    "\n",
    "# Identify vendors in the text\n",
    "identified_vendors = identify_vendors_in_text(text)\n",
    "\n",
    "# Print the identified vendors\n",
    "for vendor in identified_vendors:\n",
    "    print(vendor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8427426d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
